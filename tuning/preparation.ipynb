{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3def75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53906be",
   "metadata": {},
   "source": [
    "# Observe data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf08579",
   "metadata": {},
   "source": [
    "Data consists of the following\n",
    "- _train/images/_ - directory with train images\n",
    "- _test/images/_ - directory with test images\n",
    "- _iwildcam2022_train_annotations.json_ - file with train images metadata\n",
    "- _iwildcam2022_test_information.json_ - file with test images metadata\n",
    "- _iwildcam2022_mdv4_detections.json_ - file with detections data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c80d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28e709e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data\n",
      "├── instance_masks\n",
      "│   └── instance_masks\n",
      "├── metadata\n",
      "│   └── metadata\n",
      "├── test\n",
      "│   └── images\n",
      "└── train\n",
      "    └── images\n",
      "\n",
      "8 directories\n"
     ]
    }
   ],
   "source": [
    "_ = os.system(f'tree -d {DATA_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c63bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGES_PATH = f'{DATA_PATH}/train/images'\n",
    "TEST_IMAGES_PATH = f'{DATA_PATH}/test/images'\n",
    "\n",
    "TRAIN_INFO_PATH = f'{DATA_PATH}/metadata/metadata/iwildcam2022_train_annotations.json'\n",
    "TEST_INFO_PATH = f'{DATA_PATH}/metadata/metadata/iwildcam2022_test_information.json'\n",
    "\n",
    "DETECTIONS_INFO_PATH = f'{DATA_PATH}/metadata/metadata/iwildcam2022_mdv4_detections.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29978f04",
   "metadata": {},
   "source": [
    "## Count number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84741b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 197977\n"
     ]
    }
   ],
   "source": [
    "cmd = f'ls {TRAIN_IMAGES_PATH} | wc -l'\n",
    "print('Number of train images:', end=' ')\n",
    "_ = os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecbd5a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test images: 60029\n"
     ]
    }
   ],
   "source": [
    "cmd = f'ls {TEST_IMAGES_PATH} | wc -l'\n",
    "print('Number of test images:', end=' ')\n",
    "_ = os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b49b5",
   "metadata": {},
   "source": [
    "## Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1524a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of train image metadata:\n",
      "\n",
      "{'datetime': '2013-06-05 05:44:19.000',\n",
      " 'file_name': '8b02698a-21bc-11ea-a13a-137349068a90.jpg',\n",
      " 'height': 1080,\n",
      " 'id': '8b02698a-21bc-11ea-a13a-137349068a90',\n",
      " 'location': 3,\n",
      " 'seq_frame_num': 0,\n",
      " 'seq_id': '30048d32-7d42-11eb-8fb5-0242ac1c0002',\n",
      " 'seq_num_frames': 6,\n",
      " 'sub_location': 0,\n",
      " 'width': 1920}\n"
     ]
    }
   ],
   "source": [
    "with open(TRAIN_INFO_PATH) as file:\n",
    "    train_info = json.load(file)\n",
    "\n",
    "train_images_info = train_info['images']\n",
    "\n",
    "print('Example of train image metadata:\\n')\n",
    "pprint(train_images_info[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c06e5067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of test image metadata:\n",
      "\n",
      "{'datetime': '2013-06-09 16:01:38.000',\n",
      " 'file_name': '8b31d3be-21bc-11ea-a13a-137349068a90.jpg',\n",
      " 'height': 1024,\n",
      " 'id': '8b31d3be-21bc-11ea-a13a-137349068a90',\n",
      " 'location': 20,\n",
      " 'seq_frame_num': 0,\n",
      " 'seq_id': 'a91ebc18-0cd3-11eb-bed1-0242ac1c0002',\n",
      " 'seq_num_frames': 10,\n",
      " 'width': 1280}\n"
     ]
    }
   ],
   "source": [
    "with open(TEST_INFO_PATH) as file:\n",
    "    test_info = json.load(file)\n",
    "\n",
    "test_images_info = test_info['images']\n",
    "\n",
    "print('Example of test image metadata:\\n')\n",
    "pprint(test_images_info[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcc713db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of image detections data:\n",
      "\n",
      "{'detections': [{'bbox': [0.534, 0.464, 0.091, 0.249],\n",
      "                 'category': '1',\n",
      "                 'conf': 0.999}],\n",
      " 'file': 'test/87aaf7d4-21bc-11ea-a13a-137349068a90.jpg',\n",
      " 'max_detection_conf': 0.999}\n"
     ]
    }
   ],
   "source": [
    "with open(DETECTIONS_INFO_PATH) as file:\n",
    "    detections_info = json.load(file)\n",
    "\n",
    "image_detections_info = detections_info['images']\n",
    "\n",
    "print('Example of image detections data:\\n')\n",
    "pprint(image_detections_info[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bc15db",
   "metadata": {},
   "source": [
    "## Classes of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "500c431e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 'animal', '2': 'person', '3': 'vehicle'}\n"
     ]
    }
   ],
   "source": [
    "detection_categories = detections_info['detection_categories']\n",
    "pprint(detection_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00e31bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANIMAL_CATEGORY = '1'\n",
    "PERSON_CATEGORY = '2'\n",
    "VEHICLE_CATEGORY = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5929e9",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a84904",
   "metadata": {},
   "source": [
    "## 0. Synchronize train images info\n",
    "\n",
    "During experiments we lost 3422 training images due to one incareful command, therefore we need to synchronize image metadata with actual content of _train/images_ directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74cac458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lost images = 3422\n"
     ]
    }
   ],
   "source": [
    "num_lost_images = len(train_images_info) - 197977\n",
    "print(f'Number of lost images = {num_lost_images}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeaf543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_INFO = dict[str, str | int]\n",
    "\n",
    "\n",
    "def sync_images_info(images_info: list[IMAGE_INFO], directory: str) -> list[IMAGE_INFO]:\n",
    "    result = []\n",
    "    for image_info in images_info:\n",
    "        file_path = f'{directory}/{image_info[\"file_name\"]}'    \n",
    "        if os.path.isfile(file_path):\n",
    "            result.append(image_info)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c56afa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of training images = 197977\n"
     ]
    }
   ],
   "source": [
    "train_images_info = sync_images_info(train_images_info, TRAIN_IMAGES_PATH)\n",
    "print(f'Number of training images = {len(train_images_info)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04425181",
   "metadata": {},
   "source": [
    "## 1. Reduce dataset\n",
    "\n",
    "To make training process feasible we need to reduce dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754c3871",
   "metadata": {},
   "source": [
    "### 1.1. Leave images of one size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baf5b0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {(1920, 1080): 87237,\n",
       "             (2048, 1536): 109371,\n",
       "             (1280, 1024): 56578,\n",
       "             (1280, 720): 3484,\n",
       "             (2592, 1944): 1131,\n",
       "             (2592, 2000): 40,\n",
       "             (2825, 1810): 1,\n",
       "             (2941, 1849): 2,\n",
       "             (2833, 1873): 1,\n",
       "             (2895, 1826): 2,\n",
       "             (2778, 1818): 1,\n",
       "             (2918, 1826): 3,\n",
       "             (2794, 1795): 1,\n",
       "             (2902, 1873): 1,\n",
       "             (2949, 1865): 1,\n",
       "             (2902, 1810): 1,\n",
       "             (2778, 1857): 1,\n",
       "             (2856, 1810): 1,\n",
       "             (2879, 1826): 4,\n",
       "             (2786, 1795): 1,\n",
       "             (1795, 1222): 2,\n",
       "             (1891, 1222): 1,\n",
       "             (2926, 1841): 1,\n",
       "             (2887, 1857): 3,\n",
       "             (2933, 1795): 1,\n",
       "             (2833, 1841): 2,\n",
       "             (2926, 1865): 2,\n",
       "             (2732, 1841): 1,\n",
       "             (2833, 1849): 2,\n",
       "             (2871, 1849): 1,\n",
       "             (2848, 1849): 2,\n",
       "             (2864, 1834): 2,\n",
       "             (2895, 1841): 3,\n",
       "             (2840, 1834): 4,\n",
       "             (2887, 1810): 1,\n",
       "             (2918, 1841): 2,\n",
       "             (2910, 1849): 2,\n",
       "             (2856, 1834): 1,\n",
       "             (2871, 1834): 1,\n",
       "             (2902, 1841): 4,\n",
       "             (2918, 1810): 1,\n",
       "             (2732, 1810): 1,\n",
       "             (2802, 1834): 1,\n",
       "             (3424, 2217): 1,\n",
       "             (2825, 1849): 1,\n",
       "             (2662, 1826): 1,\n",
       "             (2646, 1818): 1,\n",
       "             (2941, 1873): 1,\n",
       "             (2833, 1826): 1,\n",
       "             (2887, 1818): 2,\n",
       "             (2949, 1857): 1,\n",
       "             (2763, 1841): 1,\n",
       "             (2848, 1834): 1,\n",
       "             (2879, 1810): 3,\n",
       "             (2910, 1818): 1,\n",
       "             (2802, 1841): 1,\n",
       "             (2817, 1795): 1,\n",
       "             (2902, 1826): 3,\n",
       "             (2848, 1841): 2,\n",
       "             (2864, 1818): 2,\n",
       "             (2739, 1772): 1,\n",
       "             (2786, 1826): 1,\n",
       "             (2933, 1857): 1,\n",
       "             (2879, 1803): 1,\n",
       "             (2809, 1818): 1,\n",
       "             (2926, 1826): 3,\n",
       "             (2895, 1873): 1,\n",
       "             (1874, 1212): 2,\n",
       "             (2918, 1818): 2,\n",
       "             (2864, 1795): 1,\n",
       "             (1812, 1196): 1,\n",
       "             (2941, 1841): 1,\n",
       "             (2840, 1826): 1,\n",
       "             (3565, 2226): 2,\n",
       "             (2949, 1834): 1,\n",
       "             (2926, 1834): 1,\n",
       "             (2856, 1826): 1,\n",
       "             (2856, 1841): 2,\n",
       "             (2856, 1818): 1,\n",
       "             (2933, 1810): 1,\n",
       "             (2848, 1826): 1,\n",
       "             (2871, 1810): 1,\n",
       "             (2864, 1841): 2,\n",
       "             (2848, 1857): 1,\n",
       "             (2771, 1849): 1,\n",
       "             (2809, 1810): 1,\n",
       "             (2825, 1834): 1,\n",
       "             (2833, 1857): 1,\n",
       "             (2910, 1826): 2,\n",
       "             (2949, 1849): 1,\n",
       "             (2918, 1857): 2,\n",
       "             (2871, 1803): 1,\n",
       "             (2833, 1810): 1,\n",
       "             (1874, 1206): 1,\n",
       "             (2902, 1849): 1,\n",
       "             (2871, 1865): 1,\n",
       "             (2933, 1849): 1,\n",
       "             (2732, 1818): 1,\n",
       "             (2964, 1849): 1,\n",
       "             (2926, 1857): 2,\n",
       "             (2421, 1849): 1,\n",
       "             (2848, 1795): 1,\n",
       "             (2902, 1818): 2,\n",
       "             (2910, 1841): 1,\n",
       "             (2887, 1865): 1,\n",
       "             (2895, 1865): 1,\n",
       "             (2949, 1803): 1,\n",
       "             (2949, 1841): 2,\n",
       "             (2918, 1795): 1,\n",
       "             (2856, 1857): 1,\n",
       "             (2910, 1803): 1,\n",
       "             (2771, 1779): 2,\n",
       "             (2871, 1826): 1,\n",
       "             (2933, 1880): 1,\n",
       "             (2825, 1826): 1,\n",
       "             (2212, 1841): 1,\n",
       "             (2887, 1826): 1,\n",
       "             (2910, 1834): 1,\n",
       "             (2910, 1810): 1,\n",
       "             (2918, 1849): 1,\n",
       "             (2957, 1865): 1,\n",
       "             (2918, 1865): 1,\n",
       "             (2895, 1810): 1,\n",
       "             (2902, 1857): 1,\n",
       "             (2941, 1803): 1,\n",
       "             (2817, 1826): 1})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "sizes = defaultdict(int)\n",
    "\n",
    "for image_info in train_images_info:\n",
    "    width, height = image_info['width'], image_info['height']\n",
    "    sizes[(width, height)] += 1\n",
    "\n",
    "for image_info in test_images_info:\n",
    "    width, height = image_info['width'], image_info['height']\n",
    "    sizes[(width, height)] += 1\n",
    "\n",
    "sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ae4876",
   "metadata": {},
   "source": [
    "Large part of images have size of 1920 x 1080. Let us remove others out of consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "142fffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_images(\n",
    "    images_info: list[IMAGE_INFO],\n",
    "    leave_size: tuple[int, int],\n",
    "    from_dir: str,\n",
    "    to_dir: str\n",
    ") -> list[IMAGE_INFO]:\n",
    "    \"\"\"Moves images of size not equal to leave_size from from_dir to to_dir\"\"\"\n",
    "\n",
    "    result = []\n",
    "    for image_info in images_info:\n",
    "        if image_info['width'] == leave_size[0] and image_info['height'] == leave_size[1]:\n",
    "            result.append(image_info)\n",
    "            continue\n",
    "        file_path = f'{from_dir}/{image_info[\"file_name\"]}'    \n",
    "        if os.path.isfile(file_path):\n",
    "            os.system(f'mv {file_path} {to_dir}')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cc462df",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IGNORED_IMAGES_PATH = f'{DATA_PATH}/train/ignored_images'\n",
    "TEST_IGNORED_IMAGES_PATH = f'{DATA_PATH}/test/ignored_images'\n",
    "\n",
    "\n",
    "if not os.path.exists(TRAIN_IGNORED_IMAGES_PATH):\n",
    "    os.makedirs(TRAIN_IGNORED_IMAGES_PATH)\n",
    "\n",
    "if not os.path.exists(TEST_IGNORED_IMAGES_PATH):\n",
    "    os.makedirs(TEST_IGNORED_IMAGES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f91dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_info = move_images(train_images_info, (1920, 1080), TRAIN_IMAGES_PATH, TRAIN_IGNORED_IMAGES_PATH)\n",
    "test_images_info = move_images(test_images_info, (1920, 1080), TEST_IMAGES_PATH, TEST_IGNORED_IMAGES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41b18d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 65036\n",
      "Number of test images: 22201\n"
     ]
    }
   ],
   "source": [
    "print('Number of train images:', len(train_images_info))\n",
    "print('Number of test images:', len(test_images_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3285740f",
   "metadata": {},
   "source": [
    "### 1.2 Reduce dataset by some percent\n",
    "\n",
    "Dataset is still large, therefore we proceed with reducing its size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf860981",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCARDED_TRAIN_IMAGES_PATH = f'{DATA_PATH}/train/discarded_images'\n",
    "DISCARDED_TEST_IMAGES_PATH = f'{DATA_PATH}/test/discarded_images'\n",
    "\n",
    "\n",
    "if not os.path.exists(DISCARDED_TRAIN_IMAGES_PATH):\n",
    "    os.makedirs(DISCARDED_TRAIN_IMAGES_PATH)\n",
    "\n",
    "if not os.path.exists(DISCARDED_TEST_IMAGES_PATH):\n",
    "    os.makedirs(DISCARDED_TEST_IMAGES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35a1fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "\n",
    "def reduce_dataset(\n",
    "    images_info: list[IMAGE_INFO],\n",
    "    from_dir: str,\n",
    "    to_dir: str,\n",
    "    reduced_size: float,\n",
    ") -> list[IMAGE_INFO]:\n",
    "    \"\"\"Leaves reduced_size images in consideration, others are move do to_dir directory\"\"\"\n",
    "\n",
    "    num_reduced = floor(reduced_size  * len(images_info))\n",
    "\n",
    "    result = []\n",
    "    for i in range(num_reduced):\n",
    "        result.append(images_info[i])\n",
    "\n",
    "    for i in range(num_reduced, len(images_info)):\n",
    "        image_info = images_info[i]\n",
    "        file_path = f'{from_dir}/{image_info[\"file_name\"]}'    \n",
    "        if os.path.isfile(file_path):\n",
    "            os.system(f'mv {file_path} {to_dir}')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c57ddfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e7f5a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_info = reduce_dataset(train_images_info, TRAIN_IMAGES_PATH, DISCARDED_TRAIN_IMAGES_PATH, SIZE)\n",
    "test_images_info = reduce_dataset(test_images_info, TEST_IMAGES_PATH, DISCARDED_TEST_IMAGES_PATH, SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37d7a8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 13007\n",
      "Number of test images: 4440\n"
     ]
    }
   ],
   "source": [
    "print('Number of train images:', len(train_images_info))\n",
    "print('Number of test images:', len(test_images_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c721cf7",
   "metadata": {},
   "source": [
    "## 2. Prepare validation set\n",
    "\n",
    "Let us extract 25% of training set images for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7eba77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_IMAGES_PATH = f'{DATA_PATH}/validation/images'\n",
    "\n",
    "\n",
    "if not os.path.exists(VALIDATION_IMAGES_PATH):\n",
    "    os.makedirs(VALIDATION_IMAGES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fe7bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from math import floor\n",
    "\n",
    "\n",
    "def extract_validation_set(\n",
    "    images_info: list[IMAGE_INFO],\n",
    "    from_directory: str,\n",
    "    to_directory: str,\n",
    "    size: int\n",
    ") -> tuple[list[IMAGE_INFO], list[IMAGE_INFO]]:\n",
    "    num_images = floor(len(images_info) * size)\n",
    "    indices = set(random.sample(range(len(images_info)), k=num_images))\n",
    "    \n",
    "    train_images_info = []\n",
    "    val_images_info = []\n",
    "\n",
    "    for ind, image_info in enumerate(images_info):\n",
    "        if ind in indices:\n",
    "            val_images_info.append(image_info)\n",
    "            file_name = image_info['file_name']\n",
    "            file_path = f'{from_directory}/{file_name}'    \n",
    "            if os.path.isfile(file_path):\n",
    "                os.system(f'mv {file_path} {to_directory}')\n",
    "        else:\n",
    "            train_images_info.append(image_info)\n",
    "\n",
    "    return train_images_info, val_images_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab18bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_info, val_images_info = extract_validation_set(train_images_info, TRAIN_IMAGES_PATH, VALIDATION_IMAGES_PATH, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6386412a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 9756\n",
      "Number of validation images: 3251\n",
      "Number of test images: 4440\n"
     ]
    }
   ],
   "source": [
    "print('Number of train images:', len(train_images_info))\n",
    "print('Number of validation images:', len(val_images_info))\n",
    "print('Number of test images:', len(test_images_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab4f046",
   "metadata": {},
   "source": [
    "## 3. Prepare labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c3c837",
   "metadata": {},
   "source": [
    "### 3.0 Preliminary actions\n",
    "\n",
    "Let us convert detections metadata from list to dict representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "616e2fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "IMAGE_DETECTIONS = dict[str, Any]\n",
    "\n",
    "\n",
    "def convert_image_detections_info(image_detections_info: list[dict]) -> dict[str, IMAGE_DETECTIONS]:\n",
    "    result = dict()\n",
    "    for info in image_detections_info:\n",
    "        file_name = info['file']\n",
    "        image_id = file_name.split('/')[1].split('.')[0]\n",
    "        result[image_id] = info['detections']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e74b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = convert_image_detections_info(image_detections_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2c682b",
   "metadata": {},
   "source": [
    "### 3.1 Create files with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6295fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LABELS_PATH = f'{DATA_PATH}/train/labels'\n",
    "VALIDATION_LABELS_PATH = f'{DATA_PATH}/validation/labels'\n",
    "TEST_LABELS_PATH = f'{DATA_PATH}/test/labels'\n",
    "\n",
    "\n",
    "if not os.path.exists(TRAIN_LABELS_PATH):\n",
    "    os.makedirs(TRAIN_LABELS_PATH)\n",
    "\n",
    "if not os.path.exists(VALIDATION_LABELS_PATH):\n",
    "    os.makedirs(VALIDATION_LABELS_PATH)\n",
    "\n",
    "if not os.path.exists(TEST_LABELS_PATH):\n",
    "    os.makedirs(TEST_LABELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37d31f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBOX = list[int]\n",
    "\n",
    "\n",
    "def get_bboxes(image_id: str, detections: dict[str, IMAGE_DETECTIONS]) -> list[BBOX]:\n",
    "    image_detections = detections[image_id]\n",
    "    bboxes = [\n",
    "        detection['bbox'] for detection in image_detections\n",
    "        if detection['category'] == ANIMAL_CATEGORY and detection['conf'] > 0.5\n",
    "    ]\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bdac632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_files(\n",
    "    images_info: list[IMAGE_INFO],\n",
    "    detections: dict[str, IMAGE_DETECTIONS],\n",
    "    directory: str\n",
    "):\n",
    "    for image_info in images_info:\n",
    "        bboxes = get_bboxes(image_info['id'], detections)        \n",
    "        file_path = f'{directory}/{image_info[\"id\"]}.txt'\n",
    "        with open(file_path, 'w') as file:\n",
    "            for bbox in bboxes:\n",
    "                file.write(f'0 {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8dbe846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_label_files(train_images_info, detections, TRAIN_LABELS_PATH)\n",
    "create_label_files(val_images_info, detections, VALIDATION_LABELS_PATH)\n",
    "create_label_files(test_images_info, detections, TEST_LABELS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6262af35",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db9a3af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data\n",
      "├── instance_masks\n",
      "│   └── instance_masks\n",
      "├── metadata\n",
      "│   └── metadata\n",
      "├── test\n",
      "│   ├── discarded_images\n",
      "│   ├── ignored_images\n",
      "│   ├── images\n",
      "│   └── labels\n",
      "├── train\n",
      "│   ├── discarded_images\n",
      "│   ├── ignored_images\n",
      "│   ├── images\n",
      "│   └── labels\n",
      "└── validation\n",
      "    ├── images\n",
      "    └── labels\n",
      "\n",
      "17 directories\n"
     ]
    }
   ],
   "source": [
    "_ = os.system(f'tree -d {DATA_PATH}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
