{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36efb148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f570ff0c",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66a583c",
   "metadata": {},
   "source": [
    "## Install yolo5 library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7378ec5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 14156, done.\u001b[K\n",
      "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
      "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
      "remote: Total 14156 (delta 56), reused 74 (delta 43), pack-reused 14060\u001b[K\n",
      "Receiving objects: 100% (14156/14156), 13.54 MiB | 537.00 KiB/s, done.\n",
      "Resolving deltas: 100% (9719/9719), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc919010",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qr ./yolov5/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01300be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov5 import train, val, detect\n",
    "from yolov5.utils import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f42c3e",
   "metadata": {},
   "source": [
    "## Prepare data config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b98a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_YAML_PATH = 'data.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61cdfef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /home/maxim/Desktop/2022-2023/icv/\n",
      "\n",
      "train: data/train/images\n",
      "val: data/validation/images\n",
      "test: data/test/images\n",
      "\n",
      "names:\n",
      "  0: animal\n"
     ]
    }
   ],
   "source": [
    "_ = os.system(f'cat {DATA_YAML_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823723d1",
   "metadata": {},
   "source": [
    "## Prepare parameters config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9105149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYP_YAML_PATH = 'hyps/default.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f5ee45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
      "lrf: 0.01  # final OneCycleLR learning rate (lr0 * lrf)\n",
      "momentum: 0.937  # SGD momentum/Adam beta1\n",
      "weight_decay: 0.0005  # optimizer weight decay 5e-4\n",
      "warmup_epochs: 3.0  # warmup epochs (fractions ok)\n",
      "warmup_momentum: 0.8  # warmup initial momentum\n",
      "warmup_bias_lr: 0.1  # warmup initial bias lr\n",
      "box: 0.05  # box loss gain\n",
      "cls: 0.5  # cls loss gain\n",
      "cls_pw: 1.0  # cls BCELoss positive_weight\n",
      "obj: 1.0  # obj loss gain (scale with pixels)\n",
      "obj_pw: 1.0  # obj BCELoss positive_weight\n",
      "iou_t: 0.20  # IoU training threshold\n",
      "anchor_t: 4.0  # anchor-multiple threshold\n",
      "# anchors: 3  # anchors per output layer (0 to ignore)\n",
      "fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n",
      "hsv_h: 0.015  # image HSV-Hue augmentation (fraction)\n",
      "hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\n",
      "hsv_v: 0.4  # image HSV-Value augmentation (fraction)\n",
      "degrees: 0.0  # image rotation (+/- deg)\n",
      "translate: 0.1  # image translation (+/- fraction)\n",
      "scale: 0.5  # image scale (+/- gain)\n",
      "shear: 0.0  # image shear (+/- deg)\n",
      "perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\n",
      "flipud: 0.0  # image flip up-down (probability)\n",
      "fliplr: 0.5  # image flip left-right (probability)\n",
      "mosaic: 1.0  # image mosaic (probability)\n",
      "mixup: 0.0  # image mixup (probability)\n",
      "copy_paste: 0.0  # segment copy-paste (probability)\n"
     ]
    }
   ],
   "source": [
    "_ = os.system(f'cat {HYP_YAML_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c7c33",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "307072a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 15\n",
    "OPTIMIZER = 'Adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "656f988d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5/yolov5s.pt, cfg=, data=data.yaml, hyp=hyps/default.yaml, epochs=1, batch_size=15, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=cuda:0, multi_scale=False, single_cls=True, optimizer=Adam, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, tensorboard=True\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
      "YOLOv5 ðŸš€ v7.0-8-g350e8eb Python-3.10.6 torch-1.13.0+cu117 CUDA:0 (NVIDIA GeForce GTX 1050, 4040MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ðŸš€ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5/yolov5s.pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07846fe6ca6441680f52c18b4e4f94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/14.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.00046875), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/maxim/Desktop/2022-2023/icv/data/train/labels.cache... 9756 images, 2055 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/maxim/Desktop/2022-2023/icv/data/validation/labels.cache... 3251 images, 699 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.31 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
      "Plotting labels to yolov5/runs/train/exp/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1myolov5/runs/train/exp\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/0      3.11G      0.073    0.02855          0         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 651/651 12:53\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 01:09\n",
      "                   all       3251       5962      0.363      0.338      0.284     0.0832\n",
      "\n",
      "1 epochs completed in 0.235 hours.\n",
      "Optimizer stripped from yolov5/runs/train/exp/weights/last.pt, 14.3MB\n",
      "Optimizer stripped from yolov5/runs/train/exp/weights/best.pt, 14.3MB\n",
      "\n",
      "Validating yolov5/runs/train/exp/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 01:14\n",
      "                   all       3251       5962      0.363      0.337      0.283     0.0832\n",
      "Results saved to \u001b[1myolov5/runs/train/exp\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Namespace(weights='yolov5/yolov5s.pt', cfg='', data='data.yaml', hyp={'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.5, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}, epochs=1, batch_size=15, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket='', cache=None, image_weights=False, device='cuda:0', multi_scale=False, single_cls=True, optimizer='Adam', sync_bn=False, workers=8, project='yolov5/runs/train', name='exp', exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias='latest', tensorboard=True, save_dir='yolov5/runs/train/exp')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.run(\n",
    "    data=DATA_YAML_PATH,\n",
    "    hyp=HYP_YAML_PATH,\n",
    "    \n",
    "    epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    optimizer=OPTIMIZER,\n",
    "    \n",
    "    single_cls=True,\n",
    "    noplots=False,\n",
    "    tensorboard=True,\n",
    "    device='cuda:0'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
